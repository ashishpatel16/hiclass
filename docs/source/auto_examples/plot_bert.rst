
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_bert.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_bert.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_bert.py:


=====================
BERT sklearn
=====================

In order to use `bert-sklearn <https://github.com/charles9n/bert-sklearn>`_ with HiClass, some of scikit-learns checks need to be disabled.
The reason is that BERT expects text as input for the features, but scikit-learn expects numerical features.
Hence, the checks will fail.
To disable scikit-learn's checks, we can simply use the parameter :literal:`bert=True` in the constructor of the local hierarchical classifier.

.. GENERATED FROM PYTHON SOURCE LINES 12-38




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Building sklearn text classifier...
    Loading bert-base-uncased model...
    Defaulting to linear classifier/regressor
    Loading Pytorch checkpoint
    train data size: 2, validation data size: 0
    Training  :   0%|          | 0/1 [00:00<?, ?it/s]This overload of add_ is deprecated:
            add_(Number alpha, Tensor other)
    Consider using one of the following signatures instead:
            add_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)
    Training  :   0%|          | 0/1 [00:05<?, ?it/s, loss=0.749]    Training  : 100%|##########| 1/1 [00:05<00:00,  5.66s/it, loss=0.749]    Training  : 100%|##########| 1/1 [00:05<00:00,  5.70s/it, loss=0.749]
    Training  :   0%|          | 0/1 [00:00<?, ?it/s]    Training  :   0%|          | 0/1 [00:08<?, ?it/s, loss=0.703]    Training  : 100%|##########| 1/1 [00:08<00:00,  8.42s/it, loss=0.703]    Training  : 100%|##########| 1/1 [00:09<00:00,  9.56s/it, loss=0.703]
    Training  :   0%|          | 0/1 [00:00<?, ?it/s]    Training  :   0%|          | 0/1 [00:03<?, ?it/s, loss=0.687]    Training  : 100%|##########| 1/1 [00:03<00:00,  3.96s/it, loss=0.687]    Training  : 100%|##########| 1/1 [00:04<00:00,  4.11s/it, loss=0.687]
    Predicting:   0%|          | 0/1 [00:00<?, ?it/s]    Predicting: 100%|##########| 1/1 [00:00<00:00,  2.40it/s]    Predicting: 100%|##########| 1/1 [00:00<00:00,  2.06it/s]
    [['Action' 'The Dark Night']
     ['Action' 'Watchmen']]






|

.. code-block:: default

    from bert_sklearn import BertClassifier
    from hiclass import LocalClassifierPerParentNode

    # Define data
    X_train = X_test = [
        "Batman",
        "Rorschach",
    ]
    Y_train = [
        ["Action", "The Dark Night"],
        ["Action", "Watchmen"],
    ]

    # Use BERT for every node
    bert = BertClassifier()
    classifier = LocalClassifierPerParentNode(
        local_classifier=bert,
        bert=True,
    )

    # Train local classifier per node
    classifier.fit(X_train, Y_train)

    # Predict
    predictions = classifier.predict(X_test)
    print(predictions)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  59.292 seconds)


.. _sphx_glr_download_auto_examples_plot_bert.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_bert.py <plot_bert.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_bert.ipynb <plot_bert.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
